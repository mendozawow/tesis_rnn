#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language spanish-mexico
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language french
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Marco Teórico
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
temas a abordar (botnets, STF, RNN, LSTM)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Botnets y Malware
\end_layout

\begin_layout Subsubsection
Definición de Botnet
\end_layout

\begin_layout Standard
Se define como Botnet al conjunto de dispositivos infectados por un bot
 que conforman una red controlada por un nodo central, denominado BotMaster,
 quien tiene la capacidad de comunicarse con cada bot y ordenar la ejecución
 de órdenes específicas, tales como scans de las redes asociadas al host
 infectado por el bot, ataques distribuidos de denegación de servicio (DDOS),
 spamming, bitcoin mining, procesamiento distribuido orientado a desencriptación
, entre otras.
\end_layout

\begin_layout Subsubsection
Ciclo de vida
\end_layout

\begin_layout Standard
Las Botnets en general siguen un conjunto de etapas a lo largo de su existencia.
 Cada etapa ofrece un conjunto de alternativas para tratar de poder responder
 ante la amenaza que representan.
 Se pueden definir las siguientes etapas 
\begin_inset CommandInset citation
LatexCommand cite
key "Hachem2011"

\end_inset

:
\end_layout

\begin_layout Enumerate

\series bold
Distribución e infección: 
\series default
En general utilizan enfoques comunes vistos en otros tipos de malware.
 En particular se ha advertido un incremento en el uso de las redes sociales
 como método para llegar a la infección del host, a través del uso de ingeniería
 social.
 Otros métodos comunes de infección los componen el envío de mails con archivos
 adjuntos comprometidos, la explotación de vulnerabilidades en alguna aplicación
 corriendo en el host remoto, la propagación de malware a través de redes
 de compartición de archivos P2P, etc.
 Habiendo infectado, el bot buscará propagarse buscando vulnerabilidades
 en otros hosts adyacentes al infectado.
 
\end_layout

\begin_layout Enumerate

\series bold
Command & Control (C&C): 
\series default
Se denomina canal C&C al conducto al conducto de comunicación mediante el
 cual el Bot Master envía órdenes al bot.
 Si bien existen diferentes modelos y topologías (IRC, HTTP, P2P, etc),
 éstos son invariantes entre los bots y hasta cierto punto ofrecen un comportami
ento parecido entre distintas Botnets.
 En esta etapa el bot establece el método de comunicación con el Master
 y la comunicación propiamente dicha.
\end_layout

\begin_layout Enumerate

\series bold
Ejecución de órdenes: 
\series default
Entre las órdenes más comunes se pueden encontrar: Ataques distribuidos
 de denegación de servicio, spamming, distribución de malware, espionaje
 y phising.
\end_layout

\begin_layout Enumerate

\series bold
Ofuscación y actualización: 
\series default
A medida que surgen nuevas tecnologías, criminales buscan la forma para
 adoptarlas o abusarlas, ya sea para facilitar la generación de ganancias,
 para incementar su escalabilidad y flexibilidad o para proveer un camuflaje
 más efectivo.
 Por otro lado, los creadores de Botnets generan nuevas versiones del bot
 con nuevas formas de explotación de vulnerabilidades dado que las técnicas
 utilizadas con anterioridad quedan obsoletas debido a que por el trabajo
 de investigadores expertos en seguridad se provee de parches que mitigan
 estas vulnerabilidades.
\end_layout

\begin_layout Subsubsection
Canal C&C
\end_layout

\begin_layout Standard
El canal utilizado para ejecutar comandos puede ser implementado utilizando
 diferentes modelos, topologías y una variedad de aplicaciones (ej, HTTP,
 P2P, IRC, etc).
 El foco de atención se centra sobre el canal C&C por dos razones principales.
 Primero, los C&Cs de una botnet son únicos e improbable que cambien entre
 los bots y sus variantes.
 Segundo, el canal C&C de una botnet es escencial para mantener a una botnet
 operativa y efectiva.
\end_layout

\begin_layout Standard
Una forma de categorizar los modelos de C&C es separar los modelos centralizados
 de los modelos distribuidos.
 Un modelo de topología centralizada se caracteriza por tener un punto central
 que envia y publica mensajes hacia y entre sus clientes.
 En este modelo centralizado, el BotMaster selecciona un host a ser el punto
 de concacto de todos los bots (servidor C&C).
 Cuando la víctima es infectada, se conectará al servidor C&C y luego esperará
 y comprobará si hay comandos pendientes del BotMaster.
 Estos servidores corren ciertos servicios como IRC y HTTP, y además cuentan
 con mecanismos para proteger sus comunicaciones.
 Por ejemplo, los canales IRC pueden ser protegidos por contraseña tanto
 por los bots como por el master para evitar ser espiados.
 La mayoría de las botnets utilizan este modelo dada la simplicidad de implement
ación y customización, y un BotMaster puede fácilmente controlar miles de
 bots utilizando el modelo centralizado.
 Asimismo, la latencia de mensajes en este modelo es baja, por lo tanto
 los BotMasters pueden coordinar y lanzar ataques de manera fácil.
 Por otro lado, el modelo centralizado tiene dos grandes debilidades: el
 riesgo de comprometer el sistema entero dado el descubrimiento del servidor,
 y la facilidad de ser detectado puesto que múltiples clientes se conectan
 al mismo punto.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Se puede hablar de las topologías del modelo centralizado: single star topology,
 multiserer star topology, hierarchical topology
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Al día de hoy, el único modelo que reemplaza al modelo centralizado es el
 modelo distribuido basado en 
\emph on
peer to peer
\emph default
 (P2P).
 El modelo P2P sigue siendo una cuestión difícil, pero de hecho el uso de
 esta técnica no es novedoso, aunque muy pocos estudios se focalizan en
 este tipo de métodos.
 Comparado con el modelo centralizado, el modelo distribuido es mucho mas
 difícil de descubrir y desmantelar.
 Dado que el sistema de comunicación no depende fuertemente de algunos servidore
s seleccionados, destruir uno o varios bots no llevará necesariamente a
 la destrucción de una Botnet completa.
 Más allá de esto, el diseño de los sistemas P2P es más complejo y no hay
 garantías de entrega de mensajes ni latencia.
 Muchas redes P2P tienen un servidor central o una lista semilla de pares
 que pueden ser contactados para agregar uno nuevo.
 Este proceso se presenta como un punto singular de falla, aunque investigadores
 han presentado un modelo híbrido P2P para solventarlo.
 Por último cabe destacar que este modelo sigue una topología aleatoria
 donde el atacante se conecta a cualquier bot de la red y envía comandos.
\end_layout

\begin_layout Subsubsection
Enfoques de detección
\end_layout

\begin_layout Standard
Al momento de hablar de los distintos enfoques de detección de botnets,
 se debe ahondar primero en la diferenciación entre las técnicas de detección
 de anomalías y las técnicas de detección de botnets.
 Tal cual como se especifica en 
\begin_inset CommandInset citation
LatexCommand cite
key "Karim2014"

\end_inset

, 
\emph on
detección de anomalías
\emph default
 en el contexto de networking hace referencia al problema de encontrar patrones
 de comunicación excepcionales en el tráfico de red que no es conforme con
 el comportamiento normal esperado.
 Por otra parte, las anomalías no operan en un ambiente supervisado.
 Esto quiere decir, en un sentido amplio, que las anomalías son los patrones
 de tráfico inusuales generado explícita o implícitamente por diversas entidades
 en un entorno de red sin control.
\end_layout

\begin_layout Standard
Por el contrario, la detección botnet se refiere a la detección de actividades
 maliciosas/anómalas que se rigen en un entorno de red controlado.
 distribuidores de malware consideran a las botnets como un medio para difundir
 las actividades maliciosas y anómalas en todo el mundo.
 Como resultado, las botnets se hicieron populares, ya que constituyen redes
 de control remoto de ordenadores secuestrados, donde el objetivo básico
 de esta red distribuida y coordinada es el de iniciar una serie de actividades
 maliciosas sobre la red, tales como phising, click-fraud, generación de
 spam, violaciones de copyright, key logging, y más importante, ataques
 de denegación de servicio.
 Es por ello que las botnets representan una gran amenaza a los recursos
 de red sobre la internet, puesto que son el medio por el cual se distribuyen
 las anomalías.
\end_layout

\begin_layout Standard
Siguiendo la categorización utilizada en 
\begin_inset CommandInset citation
LatexCommand cite
key "Karim2014"

\end_inset

, las técnicas de detección de botnets son clasificadas en dos grandes categoría
s, IDS (sistemas de detección de intrusiones) y honeynets (Provos, 2004;
 Stinson and Mitchell, 2007).
 Los IDS se subdividen además en detectores de anomalías y detectores basados
 en firmas.
\end_layout

\begin_layout Standard
Una honeynet constituye una red construida con vulnerabilidades intencionales,
 cuyo propósito es invitar a ser atacada de tal manera que tanto las actividades
 del atacante como sus métodos puedan ser estudiados y a través de esa informaci
ón incrementar la seguridad de red.
 Una honeynet recolecta información de los bots para sus análisis posterior
 para medir la tecnología utilizada, las características de la botnet y
 la intensidad del ataque.
 Asimismo, la información recolectada de los bots es utilizada para descubrir
 el sistema de C&C, susceptibilidades desconocidas, técnicas y otras herramienta
s utilizadas por el atacante y la motivación del atacante.
 Una honeynet es además utilizada para recolectar binarios de bots, los
 cuales penetran las botnets (Freiling et al., 2005; Abu Rajab et al., 2006;
 Stinson and Mitchell, 2007).
\end_layout

\begin_layout Standard
Mas allá de su utilidad, hay cierto aspectos críticos que limitan la capacidad
 de las honeynets.
 Por un lado, sus escalabilidad es limitada, dado que se requiere desplegar
 equipamiento de hardware intensivo (gateways de routers y el sistema de
 honeynet).
 Por otro lado, el descubrimiento de equipos infectados dentro de la honeynet
 también es un desafío.
 Por último, un riesgo siempre latente es que el atacante pueda tomar control
 de los honeybots para dañar otros sistemas o equipos fuera de la honeynet
 (Bethencourt et al., 2005; Zou and Cunningham, 2006).
\end_layout

\begin_layout Standard
En el caso de los IDS, estos se constituyen como una aplicación de software
 o máquina de hardware que tiene el objetivo de monitorear los servicios
 del sistema en búsqueda de actividades maliciosas o violaciones a políticas
 establecidas, y reportar esas violaciones a los administradores.
 Como se dijo previamente, las técnicas de detección utilizadas por los
 IDS se pueden subclasificar en dos tipos de enfoques, basados en firmas
 y basados en anomalías.
 Las ventajas de un IDS basado en firmas es que contienen las firmas de
 un número conocido de botnets.
 Por dar un ejemplo, SNORT (www.snort.org), uno de los IDS más conocidos actualmen
te, utiliza un esquema de detección basado en firmas.
 Sin embargo, existen varias limitaciones para este tipo de enfoque.
 Una de estas limitaciones es que el IDS requiere actualizaciones frecuentes
 al repositorio de firmas para detectar botnets nuevas (Kugisaki et al.,
 2007), mientras que el ratio de actualización de firmas es considerablemente
 bajo dado que la cantidad de anomalías va en incremento y el diagnóstico
 es un trabajo que lleva tiempo.
 Otra de las limitaciones es su incapacidad para detectar ataques de botnet
 tipo día-cero (es decir, ataques que explotan una vulnerabilidad desconocida
 para el fabricante del producto), dado es que es imposible que pueda trabajar
 para botnets desconocidas.
 De la misma manera, la detección de firmas es incapaz de detectar botnets
 con firmas mínimamente diferentes.
\end_layout

\begin_layout Standard
En contraste con la detección de firmas, el enfoque del IDS basado en anomalías
 es totalmente distinto.
 La idea básica viene de analizar varias irregularidades de tráfico de red,
 incluyendo tráfico que pasa por puertos inusuales, altos niveles de latencia,
 incrementos en el volumen de tráfico y comportamiento del sistema que de
 señales de actividad maliciosa en la red.
 Los enfoques de detección basados en anomalías se subdividen a su vez en
 enfoques orientados a hosts y a la red.
 En los enfoques orientados a hosts, cada máquina es monitoreada a fin de
 encontrar acciones sospechosas.
 El monitoreo es realizado en términos de exceso de procesamiento, acceso
 a rutinas de nivel de kernel y modificación de llamadas al sistema.
 Más allá de la importancia del monitoreo a nivel de host, este enfoque
 no es escalable, ya que se requiere que todas las maquinas sean equipadas
 con herramientas de monitoreo efectivas, tales como antiviruses y software
 de detección de spam.
 En contraposición con el enfoque basado en hosts, en el enfoque de detección
 de anomalías basado en la red se analiza el tráfico de red en modo pasivo
 o activo.
 En el monitoreo activo, se inyectan paquetes en la red para medir los tiempos
 de respuesta de la red.
 Como ejemplo de un sistema de detección de monitoreo activo se puede nombrar
 a BotProbe (Wikipedia, 2013b).
 En el monitoreo pasivo el tráfico de red pasa por equipos especializado
 que que detectan la actividad sospechosa.
 El tráfico de red observado es analizado aplicando distintas técnicas de
 detecciónde anomalías, incluyendo técnicas basadas en distancia, máquinas
 de vectores de soporte, redes neuronales, análisis de clusters, y reglas
 de asociación aprendidas.
 No requiere inyectar tráfico adicional a la red, como en el enfoque activo.
 Este enfoque monitorea pasivamente el tráfico de red con la idea de que
 el tráfico de botnet tiene características similares que pueden ser detectadas
 observando los pedidos y respuestas de tráfico durante un intervalo de
 tiempo.
 La premisa básica detrás del monitoreo pasivo es que el tráfico tiene a
 responder con un mismo patrón de comunicación en la botnet, más allá de
 la arquitectura desplegada (cliente-servidor o peer-to-peer), ya que en
 cada bot de la botnet se es instalado un programa preconfigurado que responde
 de una manera similar.
\end_layout

\begin_layout Subsection
Stratosphere Testing Framework
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Mencionar el problema de los modelos de markov para mirar hacia atrás.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Mencionar como se va el modelo de markov a medida se analiza un mayor numero
 de estados? (limite maxlen)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Stratosphere IPS (Sistema de prevención de intrusiones), es una iniciativa
 creada con el objeto de proveer a la comunidad un IPS de última generación
 basado en comportamiento.
 La metodología actual de detección de Stratosphere está basada en Modelos
 de Markov de primer orden.
 Si bien los resultados han sido prometedores y se están desarrollando mejoras
 continuamente, los modelos de primer orden de Markov sufren inconvenientes
 al momento de memorizar largas secuencias de estados.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Estrategia-de-asignación"

\end_inset

Estrategia de asignación de símbolos para construir modelos de comportamiento
 de acuerdo al proyecto Stratosphere
\begin_inset Graphics
	filename images/letter-assignment-behavioral-models.png

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Los modelos de comportamiento de conexiones maliciosas en la red, desarrollados
 en profundidad en 
\begin_inset CommandInset citation
LatexCommand cite
key "Garcia2014c"

\end_inset

 son creados a través del estudio de parámetros del tráfico de red a lo
 largo de un intervalo de tiempo.
 Este tipo de modelos han sido implementados dentro del sistema de prevención
 de intrusiones Stratosphere, a través del esfuerzo colaborativo realizado
 por dos universidades (CVUT y Universidad nacional de Cuyo) junto con otras
 organizaciones.
 El enfoque utilizado por Stratosphere IPS para modelar el comportamiento
 de una conexión comienza con la agrupación de los flujos de red de acuerdo
 a una 4-tupla compuesta por la dirección IP origen, dirección IP destino,
 el puerto de destino y el protocolo.
 De una captura de tráfico se pueden crear varias conexiones, cada una con
 su grupo de flujos.
 Para cada flujo coincidente se le aplican los siguientes pasos para computar
 su comportamiento: 1) Se extraen tres parámetros de cada flujo: tamaño,
 duración y periodicidad.
 2) Se le asigna a cada flujo un símbolo de estado de acuerdo a los parámetros
 extraídos y a la estrategia de asignación mostrada en la tabla 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Estrategia-de-asignación"

\end_inset

.
 3) Todos los estados (símbolos) de la conexión son representados como una
 cadena de caracteres y almacenados como parte del modelo de comportamiento.
 Cada conexión posee un conjunto de estados que representan el comportamiento
 tenido por la conexión en la red.
 Un ejemplo de modelo de comportamiento se muestra en la figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "Ejemplo-de-modelo"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Ejemplo-de-modelo"

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\emph on
4.R*R.R.R*a*b*a*a*b*b*a*R.R*R.R*a*a*b*a*a*a*a*
\end_layout

\end_inset

Ejemplo de modelo de comportamiento para una conexión con dirección IP origen
 10.0.2.103, con destino a la dirección 8.8.8.8 y puerto 53, a través del protocolo
 UDP.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Aún sin considerar un método de detección, los modelos de comportamiento
 basados en símbolos mostrados en la figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Estrategia-de-asignación"

\end_inset

 han probado ser un buen enfoque de visualización para ayudar a analistas
 de seguridad en sus tareas diarias.
 Para realizar la detección de comportamiento malicioso, la estrategia actual
 seguida por Stratosphere IPS es llevar a cabo un análisis basado en cadenas
 de Markov de la probabilidad de transición de un símbolo a otro.
 Más allá de que esta técnica ha probado ser efectiva en varios escenarios
 de la vida real, es un hecho de que en el análisis de cadenas de Markov,
 cada estado depende únicamente del estado anterior.
 En la sección siguiente se procederá a describir lo que se conoce como
 redes neuronales recurrentes (RNN), y un caso especial de RNN denominado
 LSTM (Long Short Term Memory).
 Las redes LSTM han probado ser capaces de construir modelos de clasificación
 sobre secuencias con dependencias a largo plazo de una manera computacionalment
e eficiente.
\end_layout

\begin_layout Subsection
Redes Neuronales Recurrentes (RNN)
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Hay que hablar del desbalanceo como uno de los problemas de las RNN
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Una red neuronal recurrente (RNN) es una clase de red neuronal artificial
 donde la red contiene al menos una conexión de retroalimentación, de tal
 manera que las activaciones pueden fluir alrededor en un bucle.
 Esto le da a la red la capacidad para realizar procesamiento temporal y
 a su vez la capacidad para aprender secuencias.
 Esta es una diferencia fundamental al compararlas con redes neuronales
 tradicionales (ej.
 Perceptrón Multicapa), donde tanto las entradas como las salidas se encuentran
 restringidas a vectores de tamaño fijo previamente definidos.
 En la figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:rnn-architectures"

\end_inset

 se presentan un conjunto de ejemplos para reforzar este concepto:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:rnn-architectures"

\end_inset

Múltiples representaciones de arquitecturas de redes neuronales.
\begin_inset Graphics
	filename rnn_examples.jpeg

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Cada rectángulo es un vector y las flechas representan funciones.
 Los vectores de entrada están representados con rojo, los vectores de salida
 con azul y los vectores verdes mantienen el estado de la red.
 Visto de izquierda a derecha, la primer figura representa una red tradicional
 sin RNN, desde una entrada fija a una salida fija (ej.
 clasificación de imágenes).
 La segunda figura muestra una arquitectura con entrada fija y Salida secuencial
 (ej.
 subtitulado de imágenes, toma una imagen como entrada y obtiene como salida
 un conjunto de palabras que la describen), mientras que la tercer figura
 presenta una entrada en formato de secuencia con una salida fija; esta
 arquitectura es usualmente el formato tradicional de un clasificador a
 partir de una entrada secuencial (ej.
 análisis de sentimientos, donde una frase es clasificada como una expresión
 sentimental positiva o negativa).
 En el cuarto caso se puede ver que tanto la entrada como la salida tienen
 un formato de secuencia (ej.
 traducción automática, una RNN lee una frase en inglés y emite una frase
 en francés).
 Para el último caso, se puede apreciar una secuencia sincronizada de entrada
 y salida (ej.
 clasificación de video donde se quiere etiquetar cada cuadro de video).
 Nótese que en cada caso no hay restricciones preestablecidas en la longitud
 de las secuencias debido a que la transformación recurrente (verde) es
 fija y puede ser aplicada tantas veces como se quiera.
 Como ejemplos concretos de la aplicación exitosa de RNN en la resolución
 de problemas que involucran el análisis de datos secuenciales podemos nombrar
 los trabajos de 
\emph on
Mikolov et.
 al.
 (2010)
\emph default
 sobre modelado de lenguaje, reconocimiento y generación de escritura a
 mano 
\emph on
Graves (2013)
\emph default
, traducción automática 
\emph on
Sutskever et al.
 (2014)
\emph default
; 
\emph on
Bahdanau et al.
 (2014)
\emph default
, reconocimiento de voz 
\emph on
Graves et al.
 (2013)
\emph default
, análisis de video
\emph on
 Donahue et al.
 (2015)
\emph default
 y subtitulado de imágenes 
\emph on
Vinyals et al.
 (2015)
\emph default
; 
\emph on
Karpathy & Fei-Fei (2015)
\emph default
.
\end_layout

\begin_layout Standard
Es importante resaltar que no existe gran diferencia entre una implementación
 de RNN y una implementación de una red tradicional.
 De hecho, como ha sido expuesto en 
\begin_inset CommandInset citation
LatexCommand cite
key "Neural2015"

\end_inset

, una RNN puede ser convertida a una red tradicional desplegándola en el
 tiempo como se puede observar en la figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:rnn-desplegada"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:rnn-desplegada"

\end_inset

Diagrama de una red neuronal recurrente desplegada en el tiempo
\begin_inset Graphics
	filename rnn/rnn_unfolding.png

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Esto significa que toda la teoría sobre el aprendizaje de la redes tradicionales
 también aplica en cierto sentido a las RNN.
\end_layout

\begin_layout Standard
La arquitectura más simple de una RNN organiza los vectores ocultos de estado
 
\begin_inset Formula $h_{t}^{l}$
\end_inset

en una matriz bidimensional, donde 
\begin_inset Formula $t=1\ldots T$
\end_inset

 es visto como tiempo y 
\begin_inset Formula $l=1\ldots L$
\end_inset

 es visto como profundidad.
 La fila inferior de vectores 
\begin_inset Formula $h_{t}^{0}=x_{t}$
\end_inset

 a profundidad cero contiene los vectores de entrada 
\begin_inset Formula $x_{t}$
\end_inset

y cada vector en la fila superior
\begin_inset Formula $\left\{ h_{t}^{L}\right\} $
\end_inset

se utiliza para predecir un vector de salida 
\begin_inset Formula $y_{t}$
\end_inset

.
 Todos los vectores intermedios 
\begin_inset Formula $h_{t}^{l}$
\end_inset

se computan con una formula de recurrencia basada en 
\begin_inset Formula $h_{t-1}^{l}$
\end_inset

y 
\begin_inset Formula $h_{t}^{l-1}$
\end_inset

.
 A través de estos vectores ocultos, cada salida 
\begin_inset Formula $y_{t}$
\end_inset

 para un tiempo 
\begin_inset Formula $t$
\end_inset

 se convierte en una función de todos los vectores de entrada hasta 
\begin_inset Formula $t,\left\{ x1,\ldots,x_{t}\right\} $
\end_inset

.
 La forma matemática precisa de la recurrencia 
\begin_inset Formula $\left(h_{t-1}^{l},h_{t}^{l-1}\right)\rightarrow h_{t}^{l}$
\end_inset

 varía dependiendo del modelo de implementación.
 Para los objetos de este trabajo se analizará el detalle de implementación
 para una RNN original así como la implementación para el modelo de red
 LSTM.
\end_layout

\begin_layout Standard
La RNN original tiene una recurrencia de la forma
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h_{t}^{l}=\tanh W^{l}\left(\begin{array}{c}
h_{t}^{l-1}\\
h_{t-1}^{l}
\end{array}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Donde se asume que todo 
\begin_inset Formula $h\in\mathbb{R^{\eta}}$
\end_inset

.
 La matriz de parámetros en cada capa tiene dimensiones 
\begin_inset Formula $\left[n\,x\,2n\right]$
\end_inset

 y la función
\begin_inset Formula $\tanh$
\end_inset

 es aplicada elemento por elemento.
 Nótese que 
\begin_inset Formula $W^{l}$
\end_inset

 varía entre las capas pero es compartida a través del tiempo.
 Se omiten los vectores de polarización por razones de brevedad.
 Interpretando la ecuación anterior, se puede ver que las entradas de la
 capa anterior en profundidad 
\begin_inset Formula $\left(h_{t}^{l-1}\right)$
\end_inset

 y anterior en tiempo 
\begin_inset Formula $\left(h_{t-1}^{l}\right)$
\end_inset

 son transformadas e interactúan a través de interacción aditiva antes de
 ser procesadas por 
\begin_inset Formula $\tanh$
\end_inset

.
\end_layout

\begin_layout Standard
En cuanto al aprendizaje en la red, esta tarea es llevada a cabo mediante
 el algoritmo de aprendizaje denominado 
\emph on
Backpropagation through time (BPTT o propagación hacia atrás a través del
 tiempo).
 
\emph default
Este algoritmo es una extensión de standard backpropagation que realiza
 descenso de gradiente (más conocido como 
\emph on
gradient descent
\emph default
) en una red completamente desplegada.
 Dada una secuencia de entrenamiento que empieza en un tiempo 
\begin_inset Formula $t_{0}$
\end_inset

 y termina en un tiempo 
\begin_inset Formula $t_{1}$
\end_inset

 , la función de costo total es simplemente la suma en el tiempo del error
 estándar 
\begin_inset Formula $E_{sse/ce}(t)$
\end_inset

 para cada intervalo de tiempo, donde la función del error estará determinada
 por el tipo de problema, ya sea una regresión ( suma de errores cuadrados,
 SSE) o un problema de clasificación (entropía cruzada, CE):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E_{total}(t_{0,}t_{1})=\sum_{t=t_{0}}^{t_{1}}E_{sse/ce}\left(t\right)
\]

\end_inset


\end_layout

\begin_layout Standard
y los cambios de peso de descenso de gradiente tienen contribuciones de
 cada intervalo de tiempo
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\triangle w_{ij}=-\eta\frac{\partial E_{total}\left(t_{0,}t_{1}\right)}{\partial w_{ij}}=-\eta\sum_{t=t_{0}}^{t_{1}}\frac{\partial E_{sse/ce}\left(t\right)}{\partial w_{ij}}
\]

\end_inset


\end_layout

\begin_layout Standard
Las derivadas parciales constituidas 
\begin_inset Formula $\partial E_{sse/ce}\left(t\right)/\partial w_{ij}$
\end_inset

 tienen aportes de las múltiples instancias de cada peso 
\begin_inset Formula $w_{ij}\in\left\{ W_{IH},W_{HH}\right\} $
\end_inset

 y dependen de las entradas y de las activaciones de las unidades ocultas
 en los intervalos de tiempo previos.
 Los errores por tanto ahora han de ser retropropagados a través del tiempo
 así como a través de la red.
\end_layout

\begin_layout Standard
Entre las consideraciones prácticas al momento de entrenar una RNN tradicional,
 existe un problema fundamental que atenta contra la capacidad de aprendizaje
 de la red: las RNN tradicionales tienen grandes dificultades a la hora
 de aprender dependencias a largo plazo (ej.
 dependencias entre intervalos que se encuentran a gran distancia, como
 podría ser en el análisis de secuencias de texto la incidencia que puede
 tener la primer palabra con la última de una misma secuencia).
 Este problema se presenta debido a lo que se conoce como 
\series bold
desvanecimiento del gradiente
\series default
, y por otro lado debido a la 
\series bold
explosión del gradiente
\series default
.
\end_layout

\begin_layout Standard
Este fenómeno se debe parcialmente al hecho de que la información que fluye
 a través de la red es sometida a múltiples etapas de multiplicación.
 Sabiendo que cualquier número multiplicado frecuentemente por un número
 ligeramente mayor a uno puede llegar a ser inmensamente grande.
 Por otro lado, su inversa, esto es, multiplicar por un número menor a uno,
 también es verdadera.
 Debido a que las capas e intervalos de tiempo de la RNN se relacionan entre
 sí mediante multiplicación, las derivadas son susceptibles a desvanecer
 o explotar.
 Para el caso de la explosión del gradiente, los valores que toma se encuentran
 tan saturados en un extremo que terminan generando una incidencia demasiado
 grande.
 Por otro lado, los gradientes desvanecientes pueden volverse demasiado
 pequeños, generando que prácticamente no tengan ninguna incidencia en el
 aprendizaje; en síntesis, la red se vuelve incapaz de aprender dependencias
 a largo plazo.
\end_layout

\begin_layout Standard
Mientras que el problema de la explosión del gradiente se puede resolver
 de manera simple, truncando o aplastando el valor, el problema del desvanecimie
nto del gradiente se vuelve realmente complejo, principalmente porque no
 es evidente cuando ocurre y porque cuando ocurre, resolver el problema
 no es una tarea simple.
 Es por esto que para solventar estas limitaciones se han propuesto nuevos
 modelos de RNN capaces de aprender dependencias a largo plazo, entre los
 cuales se destaca el modelo conocido como LSTM.
\end_layout

\begin_layout Subsection
Long Short Term Memory (LSTM) 
\end_layout

\begin_layout Paragraph
\begin_inset Note Note
status open

\begin_layout Plain Layout
VISUALIZING AND UNDERSTANDING RECURRENT NETWORKS (Andrew Karpathy) arXiv:1506.020
78v2 [cs.LG] 17 Nov 2015
\end_layout

\end_inset


\end_layout

\begin_layout Standard
La red Long Short-Term Memory (LSTM) propuesta por 
\begin_inset CommandInset citation
LatexCommand cite
key "Hochreiter1997"

\end_inset

 fue diseñada con el objetivo de mitigar las dificultades al momento de
 entrenar RNNs 
\begin_inset CommandInset citation
LatexCommand cite
key "Bengio1994"

\end_inset

.
 En particular, se observó que la dinámica de backpropagation producía que
 los gradientes desaparecieran o explotaran (fenómenos conocidos como 
\emph on
vanishing gradient
\emph default
 y 
\emph on
exploding gradient
\emph default
).
 Se descubrió más tarde que la preocupación por la explosión del gradiente
 podía ser mitigada si se restringía los gradientes a un valor maximo a
 través de heurística 
\emph on
Pascanu et al.
 (2012)
\emph default
.
 Por otro lado, LSTM fue diseñada para mitigar el problema del desvanecimiento
 del gradiente.
 Como se explica en 
\begin_inset CommandInset citation
LatexCommand cite
key "Karpathy2015"

\end_inset

, además de un vector de estado oculto 
\begin_inset Formula $h_{t}^{l}$
\end_inset

, las redes LSTM también mantienen un vector de memoria 
\begin_inset Formula $c_{t}^{l}$
\end_inset

.
 En cada intervalo de tiempo la red LSTM puede elegir leer, escribir, o
 reinicializar la celda utilizando mecanismos explícitos de compuerta.
 La forma precisa de la actualización es la siguiente:
\end_layout

\begin_layout Standard
\begin_inset Formula $\left(\begin{array}{c}
i\\
f\\
o\\
g
\end{array}\right)=\left(\begin{array}{c}
sigm\\
sigm\\
sigm\\
tanh
\end{array}\right)W^{l}\left(\begin{array}{c}
h_{t}^{l-1}\\
h_{t-1}^{l}
\end{array}\right)$
\end_inset

 
\begin_inset Formula $\mathllap{}\begin{array}{c}
c_{t}^{l}=f\odot c_{t-1}^{l}+i\odot g\\
h_{t}^{l}=o\odot tanh(c_{t}^{l})
\end{array}$
\end_inset


\end_layout

\begin_layout Standard
Aquí, las funciones sigmoideas sigm (
\emph on
fun
\emph default
ción 
\emph on
logística
\emph default
) y tanh (
\emph on
tangente hiperbólica
\emph default
) son aplicadas elemento por elemento, y 
\begin_inset Formula $W^{l}$
\end_inset

es una matriz 
\begin_inset Formula $\left[4n\,x\,2n\right]$
\end_inset

.
 Los tres vectores 
\begin_inset Formula $i,f,o\in\mathbb{R^{\eta}}$
\end_inset

son considerados como compuertas binarias que controlan si cada celda de
 memoria es actualizada, si es puesta a cero, y si su estado local se revela
 en el vector oculto, respectivamente.
 Las activaciones de estas compuertas se basan en la función sigmoide y
 por tanto se permiten variar suavemente entre cero y uno para mantener
 al modelo diferenciable.
 El vector 
\begin_inset Formula $g\in\mathbb{R^{\eta}}$
\end_inset

oscila entre -1 y 1, y se utiliza para modificar los contenidos de la memoria
 de forma aditiva.
 Esta interacción aditiva es una característica crítica del diseño de LSTM,
 debido a que durante backpropagation una operación de suma simplemente
 distribuye gradientes.
 Esto permite que los gradientes en las células de memoria c fluyan hacia
 atrás a través del tiempo sin interrupción durante largos periodos de tiempo,
 o al menos hasta que el flujo es interrumpido con la interacción multiplicativa
 de una compuerta activa de olvido.
 Por último, ha de observarse que una implementación de LSTM requiere que
 se mantengan dos vectores (
\begin_inset Formula $h_{t}^{l}$
\end_inset

 y 
\begin_inset Formula $c_{t}^{l}$
\end_inset

) en cada punto de la red.
\end_layout

\begin_layout Standard
Como deja en evidencia el trabajo realizado en 
\begin_inset CommandInset citation
LatexCommand cite
key "Hochreiter1997"

\end_inset

, la mayor ventaja que ofrece la arquitectura de red LSTM es la capacidad
 de unir dependencias que se encuentran separadas por grandes intervalos
 de tiempo.
 Por otro lado se debe resaltar que LSTM es capaz de lidiar con ruido, represent
aciones distribuidas y valores continuos.
 En contraste con autómatas de estados finitos o modelos ocultos de Markov,
 LSTM no requiere una elección a 
\emph on
priori
\emph default
 del número finito de estados; en principio es capaz de lidiar con un número
 ilimitado de estados.
\end_layout

\begin_layout Standard
Otra de las ventajas aparentes de esta arquitectura es la falta de necesidad
 de un ajuste fino de parámetros.
 LSTM trabaja bien sobre un amplio rango de parámetros como el ratio de
 aprendizaje (
\emph on
learning rate
\emph default
), polarización de la compuerta de entrada (
\emph on
input gate bias
\emph default
) y polarización de la compuerta de salida (
\emph on
output gate bias
\emph default
).
\end_layout

\begin_layout Standard
En síntesis, se puede concluir que frente a un problema de análisis de secuencia
s donde exista un interés latente de analizar las relaciones entre los component
es de las secuencias, la utilización de una red LSTM se puede considerar
 como una alternativa viable, probada y eficiente.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
LSTM, definición, consideraciones de diseño, soluciones a los problemas
 inherentes a las RNN
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Bibliografía
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Golik2013,Graves2013,Jozefowicz2015,Karpathy2015,Medsker2000,Neural2015"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Golik2013,Graves2013,Jozefowicz2015,Karpathy2015,Medsker2000,Neural2015"

\end_inset


\end_layout

\end_body
\end_document
